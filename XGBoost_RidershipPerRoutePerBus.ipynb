{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b073f8-fca4-4f5b-b38c-1948b9297b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters found: {'colsample_bytree': np.float64(0.7541666010159664), 'gamma': np.float64(0.07983126110107097), 'learning_rate': np.float64(0.0792681476866447), 'max_depth': 6, 'n_estimators': 466, 'reg_alpha': np.float64(0.6832635188254582), 'reg_lambda': np.float64(0.6099966577826209), 'subsample': np.float64(0.9332779646944658)}\n",
      "\n",
      "XGBoost Model Evaluation (Per Route Per Day with Hours Left):\n",
      "MAE: 96.26\n",
      "MSE: 46678.16\n",
      "RMSE: 216.05\n",
      "R-squared: 0.9816\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# --- Load ranked routes ---\n",
    "ranked_routes = pd.read_csv('/Users/fahmi.taib/Desktop/Deployment Code Test/top_200_routes_by_ridership.csv')\n",
    "\n",
    "# --- Load ridership data ---\n",
    "ridership_df = pd.read_csv('/Users/fahmi.taib/Desktop/Deployment Code Test/very_new_finalised_ridership_route.csv', low_memory=False)\n",
    "ridership_df['date'] = pd.to_datetime(ridership_df['date'], format='%m/%d/%y', errors='coerce')\n",
    "ridership_df = ridership_df.dropna(subset=['date'])\n",
    "\n",
    "# Append year to StartDate and EndDate, then parse as datetime\n",
    "holiday_df['StartDate'] = holiday_df['StartDate'].astype(str) + '-2024'\n",
    "holiday_df['EndDate'] = holiday_df['EndDate'].astype(str) + '-2024'\n",
    "\n",
    "holiday_df['StartDate'] = pd.to_datetime(holiday_df['StartDate'], format='%d-%b-%Y', errors='coerce')\n",
    "holiday_df['EndDate'] = pd.to_datetime(holiday_df['EndDate'], format='%d-%b-%Y', errors='coerce')\n",
    "\n",
    "holiday_df['is_holiday'] = 1\n",
    "\n",
    "# Create a list of all holiday dates between StartDate and EndDate\n",
    "all_holiday_dates = []\n",
    "for _, row in holiday_df.iterrows():\n",
    "    if pd.isna(row['StartDate']) or pd.isna(row['EndDate']):\n",
    "        continue\n",
    "    all_holiday_dates.extend(pd.date_range(start=row['StartDate'], end=row['EndDate']))\n",
    "\n",
    "# Convert to set for faster lookup\n",
    "holiday_dates_set = set(all_holiday_dates)\n",
    "\n",
    "# Then later in your ridership_df:\n",
    "ridership_df['is_holiday'] = ridership_df['date'].apply(lambda x: 1 if x in holiday_dates_set else 0)\n",
    "\n",
    "\n",
    "# Merge holiday info into ridership data\n",
    "ridership_df['is_holiday'] = ridership_df['date'].apply(lambda x: 1 if x in holiday_dates_set else 0)\n",
    "\n",
    "\n",
    "# --- Filter to top 180 routes ---\n",
    "top_routes = ranked_routes.head(180)['route_no'].astype(str)\n",
    "ridership_df = ridership_df[ridership_df['route_no'].astype(str).isin(top_routes)]\n",
    "\n",
    "# --- Aggregate ridership per route per day ---\n",
    "agg_df = ridership_df.groupby(['route_no', 'date']).agg({\n",
    "    'ridership_total': 'sum',\n",
    "    'hour': 'max',  # last hour of operation on that day for route\n",
    "    'depot': 'first',\n",
    "    'route_id': 'first',\n",
    "    'is_holiday': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# --- Calculate hours left before schedule ends ---\n",
    "END_HOUR = 24  # Adjust if your schedule ends at a different hour\n",
    "agg_df['hours_left'] = END_HOUR - agg_df['hour']\n",
    "agg_df['hours_left'] = agg_df['hours_left'].clip(lower=0)\n",
    "\n",
    "# --- Add temporal features ---\n",
    "agg_df['day_of_week'] = agg_df['date'].dt.dayofweek\n",
    "agg_df['month'] = agg_df['date'].dt.month\n",
    "\n",
    "# --- Encode categorical features ---\n",
    "for col in ['depot', 'route_id', 'route_no']:\n",
    "    agg_df[col + '_enc'], _ = pd.factorize(agg_df[col])\n",
    "\n",
    "# --- Prepare features and target ---\n",
    "features = [\n",
    "    'route_no_enc', 'day_of_week', 'month',\n",
    "    'depot_enc', 'route_id_enc', 'is_holiday', 'hours_left'\n",
    "]\n",
    "X = agg_df[features]\n",
    "y = agg_df['ridership_total']\n",
    "\n",
    "# --- Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Define XGBoost model ---\n",
    "xgb = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "# --- Hyperparameter distributions ---\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'gamma': uniform(0, 5),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1)\n",
    "}\n",
    "\n",
    "# --- Randomized Search for hyperparameter tuning ---\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "\n",
    "# --- Predict and evaluate ---\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nXGBoost Model Evaluation (Per Route Per Day with Hours Left):\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e8522c-4ba2-447b-8a42-7bca49d85042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters found: {'colsample_bytree': np.float64(0.9660854910505922), 'gamma': np.float64(2.211761148655522), 'learning_rate': np.float64(0.08193620774722096), 'max_depth': 8, 'n_estimators': 147, 'reg_alpha': np.float64(0.18286599710730733), 'reg_lambda': np.float64(0.9346139973397097), 'subsample': np.float64(0.8553082375373402)}\n",
      "\n",
      "XGBoost Model Evaluation (Per Route Per Day with Hours Left):\n",
      "MAE: 91.84\n",
      "MSE: 36646.74\n",
      "RMSE: 191.43\n",
      "R-squared: 0.9856\n",
      "Model and scaler saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import randint, uniform\n",
    "import joblib\n",
    "\n",
    "# --- Load ranked routes ---\n",
    "ranked_routes = pd.read_csv('/Users/fahmi.taib/Desktop/Deployment Code Test/top_200_routes_by_ridership.csv')\n",
    "\n",
    "# --- Load ridership data ---\n",
    "ridership_df = pd.read_csv('/Users/fahmi.taib/Desktop/Deployment Code Test/very_new_finalised_ridership_route.csv', low_memory=False)\n",
    "ridership_df['date'] = pd.to_datetime(ridership_df['date'], format='%m/%d/%y', errors='coerce')\n",
    "ridership_df = ridership_df.dropna(subset=['date'])\n",
    "\n",
    "# --- Load holiday data ---\n",
    "holiday_df = pd.read_csv('/Users/fahmi.taib/Desktop/Deployment Code Test/Holiday 2024.csv')\n",
    "\n",
    "# Append year and parse StartDate and EndDate\n",
    "holiday_df['StartDate'] = holiday_df['StartDate'].astype(str) + '-2024'\n",
    "holiday_df['EndDate'] = holiday_df['EndDate'].astype(str) + '-2024'\n",
    "\n",
    "holiday_df['StartDate'] = pd.to_datetime(holiday_df['StartDate'], format='%d-%b-%Y', errors='coerce')\n",
    "holiday_df['EndDate'] = pd.to_datetime(holiday_df['EndDate'], format='%d-%b-%Y', errors='coerce')\n",
    "\n",
    "holiday_df['is_holiday'] = 1\n",
    "\n",
    "# Create a set of all holiday dates\n",
    "all_holiday_dates = []\n",
    "for _, row in holiday_df.iterrows():\n",
    "    if pd.isna(row['StartDate']) or pd.isna(row['EndDate']):\n",
    "        continue\n",
    "    all_holiday_dates.extend(pd.date_range(start=row['StartDate'], end=row['EndDate']))\n",
    "\n",
    "holiday_dates_set = set(all_holiday_dates)\n",
    "\n",
    "# Flag holidays in ridership data\n",
    "ridership_df['is_holiday'] = ridership_df['date'].apply(lambda x: 1 if x in holiday_dates_set else 0)\n",
    "\n",
    "# --- Filter to top 180 routes ---\n",
    "top_routes = ranked_routes.head(180)['route_no'].astype(str)\n",
    "ridership_df = ridership_df[ridership_df['route_no'].astype(str).isin(top_routes)]\n",
    "\n",
    "# --- Aggregate ridership per route per day ---\n",
    "agg_df = ridership_df.groupby(['route_no', 'date']).agg({\n",
    "    'ridership_total': 'sum',\n",
    "    'hour': 'max',  # last hour of operation on that day for route\n",
    "    'depot': 'first',\n",
    "    'route_id': 'first',\n",
    "    'is_holiday': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# --- Calculate hours left before schedule ends ---\n",
    "END_HOUR = 24  # Adjust if your schedule ends at a different hour\n",
    "agg_df['hours_left'] = END_HOUR - agg_df['hour']\n",
    "agg_df['hours_left'] = agg_df['hours_left'].clip(lower=0)\n",
    "\n",
    "# --- Add temporal features ---\n",
    "agg_df['day_of_week'] = agg_df['date'].dt.dayofweek\n",
    "agg_df['month'] = agg_df['date'].dt.month\n",
    "\n",
    "# --- Encode categorical features ---\n",
    "for col in ['depot', 'route_id', 'route_no']:\n",
    "    agg_df[col + '_enc'], _ = pd.factorize(agg_df[col])\n",
    "\n",
    "# --- Prepare features and target ---\n",
    "features = [\n",
    "    'route_no_enc', 'day_of_week', 'month',\n",
    "    'depot_enc', 'route_id_enc', 'is_holiday', 'hours_left'\n",
    "]\n",
    "X = agg_df[features]\n",
    "y = agg_df['ridership_total']\n",
    "\n",
    "# --- Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Scale features ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Define XGBoost model ---\n",
    "xgb = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "# --- Hyperparameter distributions ---\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'gamma': uniform(0, 5),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1)\n",
    "}\n",
    "\n",
    "# --- Randomized Search for hyperparameter tuning ---\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "\n",
    "# --- Predict and evaluate ---\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nXGBoost Model Evaluation (Per Route Per Day with Hours Left):\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")\n",
    "\n",
    "# --- Save model and scaler ---\n",
    "import joblib\n",
    "\n",
    "joblib.dump(best_model, '/Users/fahmi.taib/Desktop/Deployment Code Test/xgb_ridership_model.pkl')\n",
    "joblib.dump(scaler, '/Users/fahmi.taib/Desktop/Deployment Code Test/xgb_feature_scaler.pkl')\n",
    "\n",
    "print(\"Model and scaler saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8767ec1-754a-4d6e-b770-1c81ca957de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in ridership_df before mapping: 1044737\n",
      "Rows in depot_df: 17503\n",
      "Rows in ridership_df after mapping: 1044737\n",
      "New column 'depot_id_new' added and saved to /Users/fahmi.taib/Desktop/Deployment Code Test/v2_very_new_finalised_ridership_with_depot.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ridership_path = \"/Users/fahmi.taib/Desktop/Deployment Code Test/very_new_finalised_ridership_route.csv\"\n",
    "depot_mapping_path = \"/Users/fahmi.taib/Desktop/Deployment Code Test/mapping_depot.csv\"\n",
    "\n",
    "ridership_df = pd.read_csv(ridership_path)\n",
    "depot_df = pd.read_csv(depot_mapping_path)\n",
    "\n",
    "print(\"Rows in ridership_df before mapping:\", len(ridership_df))\n",
    "print(\"Rows in depot_df:\", len(depot_df))\n",
    "\n",
    "# Create a mapping series from depot_df: keys=line_id, values=depot\n",
    "# If there are duplicates on line_id in depot_df, it picks the first occurrence\n",
    "line_id_to_depot = depot_df.drop_duplicates(subset=['line_id']).set_index('line_id')['depot']\n",
    "\n",
    "# Add new column by mapping line_id from ridership_df to depot_id_new from depot_df\n",
    "ridership_df['depot_id_new'] = ridership_df['line_id'].map(line_id_to_depot)\n",
    "\n",
    "print(\"Rows in ridership_df after mapping:\", len(ridership_df))\n",
    "\n",
    "output_path = \"/Users/fahmi.taib/Desktop/Deployment Code Test/v2_very_new_finalised_ridership_with_depot.csv\"\n",
    "ridership_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"New column 'depot_id_new' added and saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d32c788-b185-47a4-b5a4-a70dc2910ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in ridership_df before merge: 1044737\n",
      "Rows in depot_df: 48126222\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows in ridership_df before merge:\", len(ridership_df))\n",
    "print(\"Rows in depot_df:\", len(merged_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
